{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: modified dataset already created\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import preprocessing\n",
    "\n",
    "\n",
    "current_folder = Path()\n",
    "dataset_folder = current_folder / \"dataset\"\n",
    "images_folder = dataset_folder / \"images\"\n",
    "models_folder = current_folder / \"models\"\n",
    "logs_folder = current_folder / \"logs\"\n",
    "\n",
    "X_train, X_test, y_train, y_test = preprocessing.get_dataset()\n",
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['crosswalk', 'speedlimit', 'stop', 'trafficlight'], dtype='<U12'),\n",
       " array([114, 554,  67,  91]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.10.1-py3-none-any.whl (226 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.0/226.0 kB\u001b[0m \u001b[31m458.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=1.0.2 in /home/page/anaconda3/envs/sds_python/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/page/anaconda3/envs/sds_python/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/page/anaconda3/envs/sds_python/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.9.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/page/anaconda3/envs/sds_python/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/page/anaconda3/envs/sds_python/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (3.1.0)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.10.1 imblearn-0.0\n"
     ]
    }
   ],
   "source": [
    "! pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/page/anaconda3/envs/sds_python/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py:336: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_flat = np.reshape(X_train, (X_train.shape[0], int(np.product(X_train.shape) / X_train.shape[0])))\n",
    "\n",
    "sm = SMOTE(n_jobs=-1, random_state=42)\n",
    "X_train_os, y_train_os = sm.fit_resample(X_flat, y_train)\n",
    "\n",
    "X_train_os_rs = np.reshape(X_train_os, tuple([X_train_os.shape[0]]) + X_train.shape[1:])\n",
    "\n",
    "X_train = X_train_os_rs\n",
    "y_train = y_train_os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding\n",
    "label_enc = sklearn.preprocessing.LabelEncoder()\n",
    "y_train = label_enc.fit_transform(y_train)\n",
    "y_test = label_enc.transform(y_test)\n",
    "one_hot = sklearn.preprocessing.OneHotEncoder(sparse=False)\n",
    "y_train = one_hot.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test = one_hot.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train, y_train, test_size=0.25, random_state=54\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(y_train, axis=0) / len(y_train))\n",
    "print(np.sum(y_test, axis=0) / len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from functools import partial\n",
    "\n",
    "# Keras model\n",
    "DefaultConv2D = partial(\n",
    "    keras.layers.Conv2D, kernel_size=3, activation=\"relu\", padding=\"SAME\"\n",
    ")\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        DefaultConv2D(\n",
    "            filters=64, kernel_size=7, input_shape=list(X_train[0].shape)\n",
    "        ),  # was 28, 28, 1\n",
    "        keras.layers.MaxPooling2D(pool_size=2),\n",
    "        DefaultConv2D(filters=128),\n",
    "        DefaultConv2D(filters=128),\n",
    "        keras.layers.MaxPooling2D(pool_size=2),\n",
    "        DefaultConv2D(filters=256),\n",
    "        DefaultConv2D(filters=256),\n",
    "        keras.layers.MaxPooling2D(pool_size=2),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(units=128, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.2),  # lower less regularization\n",
    "        keras.layers.Dense(units=64, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(units=4, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"sgd\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# loss\n",
    "# sparse_categorical_crossentropy used for sparse labels (target class index)\n",
    "# categorial_cross_entropy would yield a one-hot vector (only one positive label)\n",
    "# mean_squared_error for regression\n",
    "\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=logs_folder,\n",
    "    histogram_freq=1,\n",
    ")\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=3,\n",
    "    restore_best_weights=False,\n",
    ")\n",
    "\n",
    "print(\"Start training\")\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=500,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[tensorboard_cb, early_stopping_cb],\n",
    ")\n",
    "\n",
    "# Save model\n",
    "os.makedirs(models_folder, exist_ok=True)\n",
    "model.save(models_folder / \"model1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate per class\n",
    "y_pred = model.predict(X_test)\n",
    "Y_pred = np.argmax(y_pred, axis=1)  # one-hot to index\n",
    "Y_test = np.argmax(y_test, axis=1)\n",
    "print(\n",
    "    sklearn.metrics.classification_report(\n",
    "        Y_test, Y_pred, target_names=label_enc.classes_\n",
    "    )\n",
    ")\n",
    "\n",
    "# Evaluate general\n",
    "test_results = model.evaluate(X_test, y_test)  # loss and metrics\n",
    "print(f\"Test Data - Loss: {test_results[0]:.3f}, Metrics: {test_results[1:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "706770e4ae10118d1f12cfa1b2d6781cbe938e5ca810f902c05e1c7ad3ec6c4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
